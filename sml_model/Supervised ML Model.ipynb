{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificador de Arquivos Relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento de um modelo de aprendizado de máquina supervisionado para identificar, em um conjunto de arquivos PDF, quais desses arquivos são relevantes em um contexto específico.\n",
    "\n",
    "Utiliza como dados de treinamento e teste uma base de documentos pré-classificados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Técnicas aplicadas:**\n",
    "* Processamento:\n",
    "> * Remoção de dados nulos\n",
    "> * Balanceamento de classes\n",
    "* Particionamento de dados treino e teste (+validação com cross_validation)\n",
    "* Pipeline\n",
    "* Modelos de classificação\n",
    "* Matrix de confusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumário\n",
    "1. [Importações e configurações](#p1)\n",
    "2. [Exploração dos dados](#p2)\n",
    "3. [Processamento](#p3)\n",
    "4. [Treinamento e comparativo de modelos](#p4)\n",
    "6. [Exportação](#p5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"p1\"></a>\n",
    "## 1. Importações e configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Modelos de classificação\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Processamento\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Avalição \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "#fig, ax = plt.subplots(figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove warnings de tratamento de slices de data frames\n",
    "# https://stackoverflow.com/questions/37841525/correct-way-to-set-value-on-a-slice-in-pandas\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de entrada\n",
    "\n",
    "#data_file = '/home/ubuntu/nlp/notebooks/test.csv'\n",
    "data_file = '/home/ubuntu/nlp/notebooks/pdf-status.csv'\n",
    "\n",
    "df = pd.read_csv(data_file, sep=',', low_memory=False, \n",
    "                 names=['PDF_File_Path', 'Relevant', 'Content']\n",
    "                     #, nrows=10)\n",
    "                    )\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"p2\"></a>\n",
    "# 2. Exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho do dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos das colunas\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contador\n",
    "df['Relevant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentual\n",
    "df['Relevant'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores nulos\n",
    "100 * df.isna().sum() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"p3\"></a>\n",
    "# 3. Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação de conteúdo nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nulos\n",
    "dfProc = df.dropna(subset=['Relevant', 'Content'])\n",
    "100 * dfProc.isna().sum() / len(dfProc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentual da amostra limpa relacionada a total\n",
    "print(f\"Amonstra total (100.00%): {df.Content.count()}\")\n",
    "print(f\"Amonstra limpa ({100 * dfProc.Content.count()/df.Content.count():.4}%): {dfProc.Content.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balenceamento de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observou-se que a amostra apresenta classes desbalanceadas, com uma quantidade de amostras de valor 'Relevant' 1 muito menor que a quantidade de amostras com valor 0. Dessa forma, será realizado um ressample da amostra (down sample da amostra majoritária)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe majoritária\n",
    "dfProcMaj = dfProc[dfProc['Relevant'] == 0]\n",
    "majCount = len(dfProcMaj)\n",
    "majCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe minoritária\n",
    "dfProcMin = dfProc[dfProc['Relevant'] == 1]\n",
    "minCount = len(dfProcMin)\n",
    "minCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down sample\n",
    "# Classe minoritária como 1/3 da classe majoritária\n",
    "dfProcMaj_DownSampled = dfProcMaj.sample(n=minCount*3, replace=True, random_state=42)\n",
    "\n",
    "dfProcResampled = pd.concat([dfProcMin, dfProcMaj_DownSampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProcResampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProcResampled['Relevant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProcResampled['Relevant'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentual da amostra balenceada VS da amostra total\n",
    "len(dfProcResampled) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"p4\"></a>\n",
    "# 4. Treinamento e comparativo de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes com modelos de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa entrada de saída (X, y)\n",
    "X = dfProcResampled['Content']\n",
    "y = dfProcResampled['Relevant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa dados de treino e de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativo de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O comparativo entre os modelos será reliazado via cross_val_score(). Essa técnica (https://scikit-learn.org/stable/modules/cross_validation.html) divide a amostra em três partes, permitindo que o treinamento, avaliação inicial e avaliação final sejam realizados com sets diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naïve Bayes\n",
    "nb_pipeline = Pipeline([\n",
    "                        ('tfidf', TfidfVectorizer()), \n",
    "                        ('clf', MultinomialNB()),\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions set\n",
    "predictions = nb_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(nb_pipeline, X_test, y_test);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall accuracy\n",
    "print(metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(nb_pipeline, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC\n",
    "lsvc_pipeline = Pipeline([\n",
    "                            ('tfidf', TfidfVectorizer()),\n",
    "                            ('clf', LinearSVC()),\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction set\n",
    "predictions = lsvc_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lsvc_pipeline, X_test, y_test);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(lsvc_pipeline, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DecisionTreeClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTC\n",
    "dtc_pipeline = Pipeline([\n",
    "                            ('tfidf', TfidfVectorizer()),\n",
    "                            ('clf', DecisionTreeClassifier(max_depth=30)),\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction set\n",
    "predictions = dtc_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lsvc_pipeline, X_test, y_test);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(dtc_pipeline, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, dtc_pipeline.predict(X_test), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dtc_pipeline, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"p5\"></a>\n",
    "# 5. Exportação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção do modelo mais eficaz\n",
    "model = dtc_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save to file in the current working directory\n",
    "joblib_file = \"check_relevance_mlmodel.pkl\"\n",
    "joblib.dump(model, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de utilização do modelo\n",
    "# Load from file\n",
    "joblib_model = joblib.load(joblib_file)\n",
    "\n",
    "# Calculate the accuracy and predictions\n",
    "score = joblib_model.score(X_test, y_test)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "\n",
    "y_predict = joblib_model.predict(X_test)\n",
    "y_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
